import os
import sys
import json
import yfinance as yf
import pandas as pd
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from supabase import create_client, Client
from google import genai
from dotenv import load_dotenv

# ìƒìœ„ ë””ë ‰í† ë¦¬ ì°¸ì¡°
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from config import GEMINI_MODEL_NAME

load_dotenv()

# í™˜ê²½ ë³€ìˆ˜
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
GOOGLE_API_KEY = os.getenv("GEMINI_API_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    print("âŒ í™˜ê²½ ë³€ìˆ˜(SUPABASE_URL, SUPABASE_KEY)ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    supabase = None
else:
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
genai_client = genai.Client(api_key=GOOGLE_API_KEY) if GOOGLE_API_KEY else None

def translate_company_names(en_names):
    """
    Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì—…ëª…ì„ í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë²ˆì—­í•©ë‹ˆë‹¤.
    """
    if not genai_client or not en_names:
        return {name: name for name in en_names}
    
    try:
        # ë²ˆì—­ íš¨ìœ¨ì„ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹¨
        prompt = f"""
        ë‹¤ìŒ ê¸°ì—… ë¦¬ìŠ¤íŠ¸ë¥¼ í•œêµ­ì¸ì—ê²Œ ì¹œìˆ™í•œ ê³µì‹ í•œêµ­ì–´ ê¸°ì—…ëª…ìœ¼ë¡œ ë²ˆì—­í•´ì¤˜. 
        ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´: {{"ì›ë˜ì´ë¦„": "ë²ˆì—­ëœì´ë¦„"}}
        
        {en_names}
        """
        response = genai_client.models.generate_content(
            model=GEMINI_MODEL_NAME,
            contents=prompt,
            config=genai.types.GenerateContentConfig(
                response_mime_type="application/json"
            )
        )
        return json.loads(response.text)
    except Exception as e:
        print(f"âš ï¸ ê¸°ì—…ëª… ë²ˆì—­ ì‹¤íŒ¨: {e}")
        return {name: name for name in en_names}

def get_sp100_tickers():
    """ë¯¸êµ­ ì‹œì´ ìƒìœ„ 100ëŒ€ ê¸°ì—… ë¦¬ìŠ¤íŠ¸ì™€ ì´ë¦„ì„ Wikipediaì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        url = "https://en.wikipedia.org/wiki/S%26P_100"
        headers = {'User-Agent': 'Mozilla/5.0'}
        res = requests.get(url, headers=headers)
        tables = pd.read_html(res.text)
        for table in tables:
            if 'Symbol' in table.columns and 'Name' in table.columns:
                # {Symbol: Name} ë”•ì…”ë„ˆë¦¬ ìƒì„±
                mapping = {}
                for _, row in table.iterrows():
                    symbol = str(row['Symbol']).replace('.', '-')
                    mapping[symbol] = row['Name']
                return mapping
        return {}
    except Exception as e:
        print(f"âš ï¸ S&P 100 í‹°ì»¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return []

def get_kospi_top_tickers(limit=50):
    """ë„¤ì´ë²„ ì¦ì‹œì—ì„œ ì½”ìŠ¤í”¼ ì‹œì´ ìƒìœ„ ì¢…ëª©ëª…ê³¼ ì½”ë“œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        url = "https://finance.naver.com/sise/sise_market_sum.nhn?sosok=0&page=1"
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        soup = BeautifulSoup(res.text, 'lxml')
        
        items = soup.select('a.tltle')
        mapping = {}
        for item in items[:limit]:
            code = item['href'].split('=')[-1]
            name = item.text.strip()
            mapping[f"{code}.KS"] = name
        return mapping
    except Exception as e:
        print(f"âš ï¸ KOSPI í‹°ì»¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return {}

def resolve_ticker_list():
    """ê´€ì‹¬ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ì™€ ìºì‹œëœ í•œê¸€ëª…ì„ ê²°ì •í•©ë‹ˆë‹¤."""
    # 1. Supabase 'monitored_stocks' í…Œì´ë¸” í™œìš©
    if supabase:
        try:
            res = supabase.table("monitored_stocks").select("symbol, name").eq("is_active", True).execute()
            if res.data and len(res.data) > 0:
                print(f"âœ… Supabaseì—ì„œ {len(res.data)}ê°œì˜ ì¢…ëª©ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
                mapping = {item['symbol']: item.get('name') for item in res.data}
                return list(mapping.keys()), mapping
        except Exception:
            pass

    # 2. ë™ì  ìˆ˜ì§‘ (US Top 100 + KR Top 50)
    print("ğŸŒ ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìš°ëŸ‰ì£¼ ë¦¬ìŠ¤íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤...")
    us_mapping = get_sp100_tickers()
    kr_mapping = get_kospi_top_tickers(50)
    
    combined_mapping = {**us_mapping, **kr_mapping}
    tickers = list(combined_mapping.keys())
    
    if not tickers:
        fallback = ["AAPL", "MSFT", "NVDA", "005930.KS", "000660.KS"]
        return fallback, {t: t for t in fallback}
        
    return tickers, combined_mapping

def format_revenue(value, country):
    """ë§¤ì¶œì•¡ ë‹¨ìœ„ ë³€í™˜ ë¡œì§"""
    # NaN, None, 0 ëª¨ë‘ ì²˜ë¦¬
    if value is None or value == 0 or pd.isna(value):
        return "N/A"
    
    if country == 'US':
        # ë¯¸êµ­ ë‹¬ëŸ¬ë¥¼ í•œêµ­ì‹ ì½ê¸° ë‹¨ìœ„(ì¡°, ì–µ)ë¡œ ë³€í™˜í•˜ì—¬ ì§ê´€ì„± ë†’ì„
        if value >= 1e12:
            return f"{value / 1e12:.1f}ì¡° ë‹¬ëŸ¬"
        elif value >= 1e8:
            # $1B(10ì–µ ë‹¬ëŸ¬) ì´ìƒ ë˜ëŠ” $100M(1ì–µ ë‹¬ëŸ¬) ì´ìƒ ì²˜ë¦¬
            return f"{value / 1e8:.1f}ì–µ ë‹¬ëŸ¬"
        else:
            return f"${value:,.0f}"
    else:
        # í•œêµ­ ì›í™” ë‹¨ìœ„
        if value >= 1e12:
            return f"{value / 1e12:.1f}ì¡° ì›"
        elif value >= 1e8:
            return f"{value / 1e8:.1f}ì–µ ì›"
        else:
            return f"{value:,.0f}ì›"

def fetch_earnings_data(tickers, name_mapping, days_past=14, days_future=120):
    """
    ë¯¸ë˜ ì‹¤ì  ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤ (earningsTracker ë‹´ë‹¹).
    ê³¼ê±° ë°ì´í„° ì—…ë°ì´íŠ¸ëŠ” earningsUpdater.pyê°€ ë³„ë„ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        days_past: ê³¼ê±° ë©°ì¹ ê¹Œì§€ í¬í•¨í•  ê²ƒì¸ê°€ (ê¸°ë³¸ 14ì¼)
        days_future: ë¯¸ë˜ ë©°ì¹ ê¹Œì§€ ì¡°íšŒí•  ê²ƒì¸ê°€ (ê¸°ë³¸ 120ì¼)
    
    ë¡œì§:
    - date > todayì¸ ë¯¸ë˜ ë°ì´í„°ë§Œ ìˆ˜ì§‘ (ìƒˆë¡œìš´ ì–´ë‹ ì¼ì •)
    - date <= todayì¸ ê³¼ê±° ë°ì´í„°ëŠ” ì´ë¯¸ DBì— ìˆìœ¼ë¯€ë¡œ ìŠ¤í‚µ
    """
    print(f"ğŸš€ {len(tickers)}ê°œ ì¢…ëª©ì— ëŒ€í•œ ë¯¸ë˜ ì‹¤ì  ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    
    us_tickers = [t for t in tickers if '.KS' not in t and '.KQ' not in t]
    us_en_names = [name_mapping.get(t, t) for t in us_tickers]
    
    print("ğŸ§  Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ë¯¸êµ­ ê¸°ì—…ëª…ì„ í•œê¸€ë¡œ ë³€í™˜ ì¤‘...")
    translated_names = translate_company_names(us_en_names)
    
    results = []
    for symbol in tickers:
        try:
            print(f"ğŸ” {symbol} ì¡°íšŒ ì¤‘...")
            stock = yf.Ticker(symbol)
            
            # 1. EPS ë°ì´í„° ìˆ˜ì§‘ (ê³¼ê±°/ë¯¸ë˜ ëª¨ë‘)
            df = stock.earnings_dates
            if df is None or df.empty:
                print(f"âš ï¸ {symbol}ì— ì‹¤ì  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # 2. ë¯¸ë˜ ì˜ˆìƒì¹˜ ì†ŒìŠ¤: calendar
            cal = stock.calendar
            cal_rev_est = 0
            if cal is not None and isinstance(cal, dict):
                cal_rev_est = cal.get('Revenue Average', 0)
            
            # 3. ê³¼ê±° ì‹¤ì œ ë§¤ì¶œ ì†ŒìŠ¤: quarterly_income_stmt
            q_fin = stock.quarterly_income_stmt
            
            # ê¸°ì—… ì •ë³´
            country = 'KR' if '.KS' in symbol or '.KQ' in symbol else 'US'
            company_name = name_mapping.get(symbol, symbol) if country == 'KR' else translated_names.get(name_mapping.get(symbol, symbol), name_mapping.get(symbol, symbol))
            
            # ë¡œê³  URL ì¶”ì¶œ
            info = stock.info
            website = info.get('website')
            logo_url = None
            logodev_key = os.getenv("LOGODEV_PUBLISHABLE_KEY")
            if website:
                domain = website.replace('https://', '').replace('http://', '').replace('www.', '').split('/')[0]
                if logodev_key:
                    logo_url = f"https://img.logo.dev/{domain}?token={logodev_key}"
                else:
                    logo_url = f"https://img.logo.dev/{domain}"
            if not logo_url:
                logo_url = f"https://financialmodelingprep.com/image-stock/{symbol.split('.')[0]}.png"

            # 2026ë…„ ì´í›„ ë°ì´í„°ë§Œ í•„í„°ë§
            df_filtered = df[df.index.year >= 2026].head(8)
            
            for timestamp, row in df_filtered.iterrows():
                ts_naive = timestamp.replace(tzinfo=None)
                date_key = ts_naive.strftime('%Y-%m-%d')
                
                eps_est = row.get('EPS Estimate', 0)
                
                is_past = ts_naive.date() < datetime.now().date()
                
                # âš ï¸ earningsTrackerëŠ” ë¯¸ë˜ ë°ì´í„°ë§Œ ìˆ˜ì§‘
                # ê³¼ê±° ë°ì´í„° ì—…ë°ì´íŠ¸ëŠ” earningsUpdater.pyê°€ ë‹´ë‹¹
                if is_past:
                    continue
                
                # === ë¯¸ë˜ (ë°œí‘œ ì˜ˆì • ì‹¤ì ) ===
                # EPS: earnings_datesì˜ ì˜ˆìƒì¹˜
                # ë§¤ì¶œ: calendarì˜ ì˜ˆìƒì¹˜
                
                results.append({
                    'symbol': symbol,
                    'company_name': company_name,
                    'logo_url': logo_url,
                    'date': date_key,
                    'country': country,
                    'eps_estimate': float(eps_est) if pd.notnull(eps_est) else 0,
                    'eps_actual': None,
                    'revenue_estimate': float(cal_rev_est) if cal_rev_est > 0 else 0,
                    'revenue_estimate_formatted': format_revenue(cal_rev_est, country),
                    'revenue_actual': None,
                    'revenue_actual_formatted': "N/A",
                    'updated_at': datetime.now().isoformat()
                })
            
            print(f"âœ… {symbol} ({company_name}) ë°ì´í„° ê°±ì‹  ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ {symbol} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}")
            continue
            
    return results

def sync_to_supabase(data_list):
    """
    ìˆ˜ì§‘ëœ ë¯¸ë˜ ë°ì´í„°ë¥¼ Supabaseì— ì €ì¥í•©ë‹ˆë‹¤.
    
    ì¤‘ìš”: ì‹ ê·œ ë ˆì½”ë“œëŠ” insert, ê¸°ì¡´ ë ˆì½”ë“œëŠ” updateë¡œ ì²˜ë¦¬
    â†’ ê¸°ì¡´ì˜ revenue_actual ê°’ì„ ì ˆëŒ€ ë®ì–´ì“°ì§€ ì•ŠìŒ
    """
    if not data_list or supabase is None:
        print("â„¹ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ê±°ë‚˜ Supabase ì„¤ì •ì´ ë˜ì–´ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“¤ {len(data_list)}ê°œì˜ ë°ì´í„°ë¥¼ Supabase 'earnings_calendar' í…Œì´ë¸”ì— ì €ì¥ ì¤‘...")
    
    insert_count = 0
    update_count = 0
    
    for record in data_list:
        try:
            symbol = record['symbol']
            date = record['date']
            
            # 1ï¸âƒ£ ê¸°ì¡´ ë ˆì½”ë“œ í™•ì¸
            existing = supabase.table("earnings_calendar").select("*").eq("symbol", symbol).eq("date", date).execute()
            
            if existing.data and len(existing.data) > 0:
                # 2ï¸âƒ£ ê¸°ì¡´ ë ˆì½”ë“œê°€ ìˆìœ¼ë©´ â†’ ë¯¸ë˜ ë°ì´í„°ë§Œ ì—…ë°ì´íŠ¸ (revenue_actual ë³´ì¡´!)
                existing_record = existing.data[0]
                
                update_payload = {
                    'company_name': record['company_name'],
                    'logo_url': record['logo_url'],
                    'country': record['country'],
                    'eps_estimate': record['eps_estimate'],
                    'revenue_estimate': record['revenue_estimate'],
                    'revenue_estimate_formatted': record['revenue_estimate_formatted'],
                    'updated_at': record['updated_at']
                    # âš ï¸ revenue_actual, revenue_actual_formattedëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ì•ŠìŒ!
                    # ê¸°ì¡´ ê°’ì„ ë³´ì¡´í•˜ë ¤ë©´ ë¹ˆ í•„ë“œë§Œ ë³´ë‚¸ë‹¤
                }
                
                supabase.table("earnings_calendar").update(update_payload).eq("symbol", symbol).eq("date", date).execute()
                print(f"  ğŸ”„ {symbol} ({date}) ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ë§¤ì¶œê°’ ë³´ì¡´)")
                update_count += 1
            else:
                # 3ï¸âƒ£ ì‹ ê·œ ë ˆì½”ë“œ â†’ insert
                supabase.table("earnings_calendar").insert(record).execute()
                print(f"  âœ¨ {symbol} ({date}) ì‹ ê·œ ì¶”ê°€")
                insert_count += 1
        
        except Exception as e:
            print(f"  âŒ {record['symbol']} ({record['date']}) ì €ì¥ ì‹¤íŒ¨: {e}")
            continue
    
    print(f"âœ… ì €ì¥ ì™„ë£Œ (ì‹ ê·œ: {insert_count}, ì—…ë°ì´íŠ¸: {update_count})")

if __name__ == "__main__":
    ticker_list, name_mapping = resolve_ticker_list()
    earnings_data = fetch_earnings_data(ticker_list, name_mapping)
    sync_to_supabase(earnings_data)
