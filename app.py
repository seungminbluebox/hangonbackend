import feedparser
from google import genai
from supabase import create_client, Client
import json
import os
from dotenv import load_dotenv

# 1. í™˜ê²½ ë³€ìˆ˜ ë° í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
client = genai.Client(api_key=GEMINI_API_KEY)
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# 2. ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ (êµ¬ê¸€ ë‰´ìŠ¤ RSS í†µì¼)
def fetch_all_candidate_news():
    candidates = {"KR": [], "US": [], "Global": []}

    # A. í•œêµ­ (êµ¬ê¸€ ë‰´ìŠ¤ - ê²½ì œ í‚¤ì›Œë“œ)
    try:
        kr_feed = feedparser.parse("https://news.google.com/rss/search?q=%EA%B2%BD%EC%A0%9C+%EA%B8%88%EB%A6%AC+%EC%8B%9C%EC%9E%A5+when:1d&hl=ko&gl=KR&ceid=KR:ko")
        for entry in kr_feed.entries[:15]:
            candidates["KR"].append({"title": entry.title, "url": entry.link})
    except Exception as e:
        print(f"í•œêµ­ ë‰´ìŠ¤ ìˆ˜ì§‘ ì—ëŸ¬: {e}")

    # B. ë¯¸êµ­ (êµ¬ê¸€ ë‰´ìŠ¤ US Business)
    try:
        us_feed = feedparser.parse("https://news.google.com/rss/search?q=business+finance+stock+market+when:1d&hl=en-US&gl=US&ceid=US:en")
        for entry in us_feed.entries[:15]:
            candidates["US"].append({"title": entry.title, "url": entry.link})
    except Exception as e:
        print(f"ë¯¸êµ­ ë‰´ìŠ¤ ìˆ˜ì§‘ ì—ëŸ¬: {e}")

    # C. ê¸€ë¡œë²Œ (êµ¬ê¸€ ë‰´ìŠ¤ World Economy)
    try:
        global_feed = feedparser.parse("https://news.google.com/rss/search?q=world+economy+when:1d&hl=ko&gl=KR&ceid=KR:ko")
        for entry in global_feed.entries[:15]:
            candidates["Global"].append({"title": entry.title, "url": entry.link})
    except Exception as e:
        print(f"ê¸€ë¡œë²Œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì—ëŸ¬: {e}")

    return candidates


# 3. Gemini í•„í„°ë§ ë° ìš”ì•½ í•¨ìˆ˜
def get_curated_summary(news_list):
    id_map = {}
    all_candidates_text = ""

    # [ë³€ê²½ ì‚¬í•­] ëª¨ë“  ì¹´í…Œê³ ë¦¬ì˜ í›„ë³´ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í†µí•©í•˜ì—¬ ID ë¶€ì—¬
    global_index = 0
    for cat in ["KR", "US", "Global"]:
        for item in news_list[cat]:
            news_id = f"NEWS_{global_index}"
            id_map[news_id] = item
            # ì¶œì²˜ ì •ë³´ëŠ” ì£¼ì§€ ì•Šê³  ì œëª©ë§Œ ì œê³µí•˜ì—¬ ë‚´ìš©ì— ì§‘ì¤‘í•˜ê²Œ í•¨
            all_candidates_text += f"ID: {news_id}\nì œëª©: {item['title']}\n\n"
            global_index += 1

    prompt = f"""
    ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ê²½ì œ ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ {global_index}ê°œì˜ ê¸°ì‚¬ í›„ë³´ë“¤ì„ ë¶„ì„í•˜ì—¬ 
    ì˜¤ëŠ˜ì˜ í•µì‹¬ ë‰´ìŠ¤ 5ê°œë¥¼ ì„ ì •í•˜ê³  ìš”ì•½í•˜ì„¸ìš”.

    [ë‰´ìŠ¤ í›„ë³´ ëª©ë¡]
    {all_candidates_text}
    
    [ì„ ì • ê¸°ì¤€]
    1. ë‰´ìŠ¤ê°€ ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥ì´ í°ê°€?
    2. ì „ë§, ì˜ˆì¸¡ë³´ë‹¨ í˜„ì¬ ìƒí™©ì„ ëª…í™•íˆ ì„¤ëª…í•˜ëŠ” ë‰´ìŠ¤ì¸ê°€?
    3. ì§€ìˆ˜, í™˜ìœ¨, ê¸ˆë¦¬, ì¤‘ìš”í•œ ì •ì±… ìœ„ì£¼ì˜ ë‰´ìŠ¤ì¸ê°€?
    4. êµ­ê°€ ì •ì±…, ê¸ˆë¦¬, í™˜ìœ¨ë“± ê³¼ ê°™ì€ ì£¼ìš” ì´ìŠˆì¸ê°€?
    5. ê¸€ë¡œë²Œ ë¹…í…Œí¬ë‚˜ ì£¼ìš” ì‚°ì—…ì˜ íŒë„ë¥¼ ë°”ê¿€ ë§Œí•œ ì‚¬ê±´ì¸ê°€?
    7. ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ì—ì„œ ë‚˜ì˜¨ ë‰´ìŠ¤ì¸ê°€?
    8. ê²°ê³¼ë¬¼ì€ ë°˜ë“œì‹œ í•œêµ­ 2ê°œ, ë¯¸êµ­ 2ê°œ, ê¸€ë¡œë²Œ 1ê°œì—¬ì•¼ í•©ë‹ˆë‹¤.
    9. ê¸°ìì˜ ì˜ê²¬ì´ ì•„ë‹Œ ê°ê´€ì  ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ë‰´ìŠ¤ì—¬ì•¼ í•©ë‹ˆë‹¤.
    10. ëª¨ë“  ìš”ì•½ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    11. ì´ 5ê°œë¥¼ ì„ ì •: í•œêµ­ 2ê°œ, ë¯¸êµ­ 2ê°œ, ê¸€ë¡œë²Œ 1ê°œ í•„ìˆ˜.
    13. ìš”ì•½ ìŠ¤íƒ€ì¼: '~í•¨', '~ìŒ'ìœ¼ë¡œ ëë‚˜ëŠ” ê°œì¡°ì‹ ìš”ì•½ (3ê°œ í¬ì¸íŠ¸).
    16. ì„ ì •ëœ ë‰´ìŠ¤ì˜ ìš”ì•½ì„ ì‘ì„±í•  ë•Œ, í•´ë‹¹ IDì— ê·€ì†ëœ ì›ë³¸ URLì„ ì ˆëŒ€ë¡œ ë³€ê²½í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì œëª©ê³¼ ì„ì§€ ë§ˆì„¸ìš”.
    17. ê° ë‰´ìŠ¤ì˜ keywordì— ë§ˆì§€ë§‰ì— keywordì— ë§ëŠ” ì´ëª¨ì§€ ì‚¬ìš©(ê°ì • ì´ëª¨ì§€ëŠ” ê¸ˆì§€)
    18. ë¹„ìŠ·í•œ ì£¼ì œëŠ” í”¼í•˜ê³  ë‹¤ì–‘í•œ ì´ìŠˆ ì„ ì •
    ê²°ê³¼ì—ëŠ” ë°˜ë“œì‹œ ì„ ì •í•œ ë‰´ìŠ¤ì˜ 'ID'ë¥¼ 'selected_id' í•„ë“œì— ë‹´ì•„ ë°˜í™˜í•˜ì„¸ìš”.
    
    [ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ë° ì„ ì • ê¸°ì¤€ (ë§¤ìš° ì¤‘ìš”)]
    1. ì¶œì²˜ ì–¸ì–´ì™€ ìƒê´€ì—†ì´ ê¸°ì‚¬ì˜ 'í•µì‹¬ ì£¼ì œ'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë¥¼ ë‹¤ì‹œ ë¶„ë¥˜í•˜ì„¸ìš”.
       - KR: ëŒ€í•œë¯¼êµ­ ê²½ì œ, ì •ì±…, ê¸°ì—…, êµ­ë‚´ ì‹œì¥ ì´ìŠˆ
       - US: ë¯¸êµ­ ê²½ì œ(Fed, ê¸ˆë¦¬), ì›”ìŠ¤íŠ¸ë¦¬íŠ¸, ë¯¸êµ­ ë¹…í…Œí¬ ê¸°ì—… ì´ìŠˆ
       - Global: ê¸€ë¡œë²Œ ë§¤í¬ë¡œ íŠ¸ë Œë“œ, êµ­ì œê¸°êµ¬(IMF, OECD), ì¤‘ë™/ìœ ëŸ½ ë“± ë‹¤êµ­ì  ì˜í–¥ë ¥ ì´ìŠˆ
        [ì‘ì„± ê°€ì´ë“œ]
    - ëª¨ë“  ìš”ì•½ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    - ìš”ì•½ ìŠ¤íƒ€ì¼: '~í•¨', '~ìŒ'ìœ¼ë¡œ ëë‚˜ëŠ” ê°œì¡°ì‹ ìš”ì•½ (3ê°œ í¬ì¸íŠ¸).
    - keyword: ì´ìŠˆë¥¼ ì§ê´€ì ìœ¼ë¡œ ì„¤ëª…í•˜ëŠ” ë¬¸ì¥ (ì¶”ìƒì ì¸ ì œëª© ëŒ€ì‹  êµ¬ì²´ì ì¸ ì‚¬ê±´ ë‚´ìš©ì„ ëª…ì‹œ).
    - summary: ì‹œì¥ ì „ë§/ì‹œì‚¬ì  ì„¹ì…˜ì—ì„œë„ ì‹¤ì œ ë¶„ì„ ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±.
    - ì´ëª¨ì§€: keyword ë§ˆì§€ë§‰ì— ì£¼ì œì™€ ì–´ìš¸ë¦¬ëŠ” ì´ëª¨ì§€ ì‚¬ìš© (ê°ì • ì´ëª¨ì§€ ì œì™¸).

    [ì¶œë ¥ í˜•ì‹]
    ë°˜ë“œì‹œ JSON ìŠ¤í‚¤ë§ˆ í˜•ì‹ì„ ì¤€ìˆ˜í•˜ì„¸ìš”.
    [
      {{
        "category": "KR | US | Global",
        "keyword": "ì´ìŠˆë¥¼ ì§ê´€ì ìœ¼ë¡œ ì„¤ëª…í•˜ëŠ” ë¬¸ì¥",
        "summary": "- ìš”ì•½ ë‚´ìš© 1\\n- ìš”ì•½ ë‚´ìš© 2\\n- ì‹œì¥ ì „ë§/ì‹œì‚¬ì ",
        "selected_id": "ì„ ì •í•œ ë‰´ìŠ¤ì˜ ID (ì˜ˆ: KR_0)"
      }}
    ]
    """

    response = client.models.generate_content(
        model="gemini-2.0-flash", # ì†ë„ì™€ ì„±ëŠ¥ì´ ê· í˜• ì¡íŒ ëª¨ë¸
        contents=prompt,
        config={'response_mime_type': 'application/json'}
    )
    
    raw_results = json.loads(response.text)
    
    # 2. IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì›ë³¸ URL ë§¤ì¹­ (íŒŒì´ì¬ì—ì„œ ìˆ˜í–‰)
    final_results = []
    for res in raw_results:
        news_id = res.get("selected_id")
        original_news = id_map.get(news_id)
        
        if original_news:
            res["links"] = [{"title": original_news["title"], "url": original_news["url"]}]
            # selected_idëŠ” DB ì €ì¥ ì‹œ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ì‚­ì œ ê°€ëŠ¥
            del res["selected_id"]
            final_results.append(res)
            
    return final_results

# 4. ì‹¤í–‰ ë¡œì§
def main():
    print("ğŸš€ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
    candidates = fetch_all_candidate_news()
    if not candidates:
        print("âŒ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    print(f"ğŸ§ {len(candidates)}ê°œì˜ í›„ë³´ ì¤‘ 5ê°œ ì„ ë³„ ë° ìš”ì•½ ì¤‘...")
    try:
        final_news = get_curated_summary(candidates)
        # 5. Supabase ì €ì¥
        for item in final_news:
            supabase.table("daily_news").insert(item).execute()
        
        print("âœ… ì„±ê³µì ìœ¼ë¡œ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ìš”ì•½ ë° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

main()