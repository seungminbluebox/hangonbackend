import os
import sys
import time
import json
import requests
import pandas as pd
from datetime import datetime
from bs4 import BeautifulSoup
from supabase import create_client, Client
import google.generativeai as genai
from dotenv import load_dotenv

# ìƒìœ„ ë””ë ‰í† ë¦¬ ì°¸ì¡°
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from config import GEMINI_MODEL_NAME
from news.push_notification import send_push_to_all

load_dotenv()

# í™˜ê²½ ë³€ìˆ˜
GOOGLE_API_KEY = os.getenv("GEMINI_API_KEY")
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel(GEMINI_MODEL_NAME)
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

def fetch_credit_balance_history(pages=10):
    """
    ë„¤ì´ë²„ ì¦ê¶Œì—ì„œ ì‹ ìš©ìœµì ì”ê³  íˆìŠ¤í† ë¦¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    1í˜ì´ì§€ë‹¹ ì•½ 15~20ì¼ì¹˜ ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤. 10í˜ì´ì§€ë©´ ì•½ 1ë…„ì¹˜(ì˜ì—…ì¼ ê¸°ì¤€)ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    print(f"ğŸŒ ë„¤ì´ë²„ ì¦ê¶Œì—ì„œ ì‹ ìš©ìœµì ì”ê³  ìˆ˜ì§‘ ì¤‘ (í˜ì´ì§€: {pages})...")
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    
    collected_data = []
    
    for page in range(1, pages + 1):
        url = f"https://finance.naver.com/sise/sise_deposit.naver?page={page}"
        try:
            response = requests.get(url, headers=headers)
            response.encoding = 'euc-kr'
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ë°ì´í„° í…Œì´ë¸” ì°¾ê¸°
            table = soup.find('table', {'class': 'type_1'})
            if not table:
                continue
                
            rows = table.find_all('tr')
            for row in rows:
                cols = row.find_all('td')
                if len(cols) >= 5:
                    date_str = cols[0].text.strip()
                    if not date_str or '.' not in date_str:
                        continue
                    
                    # ë‚ ì§œ í˜•ì‹ ë³€í™˜ (25.01.24 -> 2025-01-24)
                    try:
                        # NaverëŠ” ë³´í†µ YY.MM.DD í˜•ì‹ì„ ì‚¬ìš©í•¨
                        date = datetime.strptime(date_str, "%y.%m.%d").strftime("%Y-%m-%d")
                    except ValueError:
                        try:
                            # í˜¹ì‹œ ëª¨ë¥¼ YYYY.MM.DD í˜•ì‹ ëŒ€ì‘
                            date = datetime.strptime(date_str, "%Y.%m.%d").strftime("%Y-%m-%d")
                        except ValueError:
                            continue
                    
                    # ë‚ ì§œ | ê³ ê°ì˜ˆíƒê¸ˆ | ëŒ€ë¹„ | ì‹ ìš©ìœµì | ëŒ€ë¹„ ... ìˆœì„œì„
                    try:
                        # ê³ ê°ì˜ˆíƒê¸ˆ (2ë²ˆì§¸ ì»¬ëŸ¼ - ì¸ë±ìŠ¤ 1)
                        deposit = int(cols[1].text.strip().replace(',', '')) * 100000000
                        # ì‹ ìš©ìœµì í•©ê³„ (4ë²ˆì§¸ ì»¬ëŸ¼ - ì¸ë±ìŠ¤ 3)
                        total = int(cols[3].text.strip().replace(',', '')) * 100000000
                        
                        collected_data.append({
                            'date': date,
                            'customer_deposit': deposit,
                            'total': total
                        })
                    except (ValueError, IndexError):
                        continue
            
            time.sleep(0.5) # ì„œë²„ ë¶€í•˜ ë°©ì§€
        except Exception as e:
            print(f"âš ï¸ {page}í˜ì´ì§€ ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬: {e}")
            
    return collected_data

def sync_to_supabase(data_list):
    if not data_list:
        return
    
    print(f"ğŸ“¤ {len(data_list)}ê°œì˜ ë°ì´í„°ë¥¼ Supabaseì— ë™ê¸°í™” ì¤‘...")
    try:
        # ë°ì´í„°ê°€ ë§ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ upsert ì‚¬ìš©
        supabase.table("credit_balance_history").upsert(data_list).execute()
        print("âœ… ì‹ ìš©ìœµì íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ Supabase ë™ê¸°í™” ì—ëŸ¬: {e}")

def analyze_credit_sentiment(history_df):
    if history_df.empty:
        return None
    
    # ìµœì‹  ë°ì´í„°
    latest = history_df.iloc[-1]
    latest_total_trillion = latest['total'] / 1000000000000
    latest_deposit_trillion = latest['customer_deposit'] / 1000000000000
    ratio = (latest['total'] / latest['customer_deposit']) * 100
    
    # ìµœê·¼ 30ì¼ê°„ì˜ ë°ì´í„° ì¤€ë¹„
    recent_30 = history_df.tail(30).to_dict(orient='records')
    
    print("ğŸ¤– AI ë¶„ì„ ì‹œì‘ (ì˜ˆíƒê¸ˆ ëŒ€ë¹„ ì‹ ìš©ì”ê³  ë¹„ìœ¨)...")
    
    prompt = f"""
    ë‹¹ì‹ ì€ í•œêµ­ ì£¼ì‹ ì‹œì¥ì˜ ìˆ˜ì„ ì „ëµê°€ì…ë‹ˆë‹¤. 
    ë‹¤ìŒ 'ê³ ê°ì˜ˆíƒê¸ˆ(ì‚´ ëˆ)'ê³¼ 'ì‹ ìš©ìœµì ì”ê³ (ë¹Œë¦° ëˆ)' ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ ì‹œì¥ì˜ ê¸°ì´ˆ ì²´ë ¥ê³¼ ê³¼ì—´ë„ë¥¼ ë¶„ì„í•´ ì£¼ì„¸ìš”.
    
    ë°ì´í„° (ìµœì‹  30ì¼):
    {json.dumps(recent_30, indent=2, ensure_ascii=False)}
    
    í˜„ì¬ ìƒíƒœ:
    - ê³ ê°ì˜ˆíƒê¸ˆ: {latest_deposit_trillion:.2f}ì¡° ì›
    - ì‹ ìš©ìœµì ì”ê³ : {latest_total_trillion:.2f}ì¡° ì›
    - ì˜ˆíƒê¸ˆ ëŒ€ë¹„ ì‹ ìš© ë¹„ìœ¨: {ratio:.2f}%

    ì°¸ê³  ë¶„ì„ ê¸°ì¤€:
    1. ë¹„ìœ¨(ì‹ ìš©/ì˜ˆíƒê¸ˆ)ì´ 20% ì´í•˜ë©´ ë§¤ìš° ì•ˆì „ ë° ë°”ë‹¥ê¶Œ.
    2. ë¹„ìœ¨ì´ 25% ~ 30% ìˆ˜ì¤€ì´ë©´ ì¼ë°˜ì ì¸ ìˆ˜ì¤€.
    3. ë¹„ìœ¨ì´ 35%ë¥¼ ë„˜ì–´ê°€ë©´ ì‹œì¥ì˜ ì‹¤ë¬¼ í˜„ê¸ˆë³´ë‹¤ ë¹šì˜ ì†ë„ê°€ ë¹ ë¥¸ ê³¼ì—´ê¶Œ.
    4. ë¹„ìœ¨ì´ 40%ì— ìœ¡ë°•í•˜ë©´ í•˜ë½ ì‹œ ë°˜ëŒ€ë§¤ë§¤ë¡œ ì¸í•œ í­ë½ ë¦¬ìŠ¤í¬ê°€ ë§¤ìš° í° ìƒíƒœ.
    
    ë¶„ì„ ê°€ì´ë“œ:
    - ë‹¨ìˆœíˆ ì‹ ìš©ì”ê³ ê°€ ë†’ì€ ê²ƒë³´ë‹¤, 'ì˜ˆíƒê¸ˆì´ ë”°ë¼ì™€ì£¼ê³  ìˆëŠ”ì§€'ë¥¼ ì¤‘ì ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.
    - ì˜ˆíƒê¸ˆì€ ì¤„ì–´ë“œëŠ”ë° ì‹ ìš©ë§Œ ëŠ˜ì–´ë‚˜ëŠ” ìƒí™©(ê´´ë¦¬ ë°œìƒ)ì´ë¼ë©´ ê°•í•œ ê²½ê³ ë¥¼ ë³´ë‚´ì„¸ìš”.
    - 'í¼ì„¼íŠ¸' ë˜ëŠ” 'í¼ì„¼íŠ¸í¬ì¸íŠ¸'ë¼ëŠ” ë‹¨ì–´ ëŒ€ì‹  ë°˜ë“œì‹œ '%' ê¸°í˜¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    - ë¶„ì„(analysis)ì€ ë°˜ë“œì‹œ 2~3ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ê° ë¬¸ì¥ì€ ê°œí–‰ë¬¸ì(\n)ë¥¼ ë„£ì–´ í•œ ì¤„ì”© ëŠì–´ì„œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
    - ë¶ˆí•„ìš”í•œ ì„œìˆ ì€ ìƒëµí•˜ê³ , í•œ ëˆˆì— ë“¤ì–´ì˜¤ë„ë¡ ë§¤ìš° ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
    - ëŠë‚Œí‘œ, ë¬¼ê²°í‘œ ê¸ˆì§€. ì „ë¬¸ì„±ê³¼ ì‹ ë¢°ê°ì´ ëŠê»´ì§€ëŠ” ê°„ê²°í•œ ë¬¸ì²´ ì‚¬ìš©.
    - íŠ¹ìˆ˜ë¬¸ì ** ì‚¬ìš© ê¸ˆì§€.
    - íˆ¬ì ê¶Œìœ ê°€ ì•„ë‹Œ í˜„ìƒ ë¶„ì„ì„ì„ ëª…í™•íˆ í•˜ë˜, ë‹¨ì–¸ì ì¸ í‘œí˜„ì€ í”¼í•˜ì„¸ìš”.
    - ì†Œìˆ˜ì  ì‚¬ìš© ê¸ˆì§€

    ê²°ê³¼ í˜•ì‹: ë°˜ë“œì‹œ JSON ë¸”ë¡ í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ê¸ˆì§€í•©ë‹ˆë‹¤.
    JSON êµ¬ì¡° ì˜ˆì‹œ:
    {{
      "title": "ì‹œì¥ ì‹ ìš©ì”ê³  ë¶„ì„ 1ì¤„ ìš”ì•½",
      "summary": "ì•ˆì „/ë³´í†µ/ê³¼ì—´ ì—¬ë¶€",
      "analysis": "ë¶„ì„ ì²« ë²ˆì§¸ ë¬¸ì¥\në¶„ì„ ë‘ ë²ˆì§¸ ë¬¸ì¥",
      "recommendation": ["ì•¡ì…˜ 1", "ì•¡ì…˜ 2", "ì•¡ì…˜ 3"]
    }}
    """
    
    try:
        # ì•ˆì „ ì„¤ì • ì¶”ê°€ (ê¸ˆìœµ ë¶„ì„ ì‹œ ì°¨ë‹¨ ë°©ì§€)
        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]

        response = model.generate_content(prompt, safety_settings=safety_settings)
        
        # ì‘ë‹µ ê²€ì¦
        if not response.candidates or not response.candidates[0].content.parts:
            print(f"âš ï¸ AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨ (Finish Reason: {response.candidates[0].finish_reason if response.candidates else 'Unknown'})")
            return None
            
        text = response.text
        if "```json" in text:
            text = text.split("```json")[1].split("```")[0]
        elif "```" in text:
            text = text.split("```")[1].split("```")[0]
        
        res_data = json.loads(text.strip())
        return res_data
    except Exception as e:
        print(f"AI Analysis Error: {e}")
        return None

def update_analysis(analysis_data, latest_data):
    if not analysis_data:
        return
        
    # JSON ì§ë ¬í™” ì‹œ NaN ì²˜ë¦¬
    clean_latest_data = {}
    for k, v in latest_data.items():
        if isinstance(v, float) and (pd.isna(v) or pd.isinf(v)):
            clean_latest_data[k] = 0
        else:
            clean_latest_data[k] = v

    payload = {
        "id": 1, # ê³ ì • ID
        "title": analysis_data.get("title"),
        "summary": analysis_data.get("summary"),
        "analysis": analysis_data.get("analysis"),
        "recommendation": analysis_data.get("recommendation"),
        "latest_data": clean_latest_data,
        "updated_at": datetime.now().isoformat()
    }
    
    try:
        supabase.table("credit_balance_analysis").upsert(payload).execute()
        print("âœ… ì‹ ìš©ìœµì ë¶„ì„ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì—ëŸ¬: {e}")

def get_latest_date_from_db():
    """DBì—ì„œ ê°€ì¥ ìµœì‹  ë°ì´í„°ì˜ ë‚ ì§œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        res = supabase.table("credit_balance_history").select("date").order("date", desc=True).limit(1).execute()
        if res.data:
            return res.data[0]['date']
    except Exception as e:
        print(f"âš ï¸ DB ë‚ ì§œ í™•ì¸ ì¤‘ ì—ëŸ¬: {e}")
    return None

def get_latest_analysis_date_from_db():
    """DBì— ì €ì¥ëœ ê°€ì¥ ìµœì‹  ë¶„ì„ì˜ ê¸°ì¤€ ë‚ ì§œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        res = supabase.table("credit_balance_analysis").select("latest_data").eq("id", 1).single().execute()
        if res.data and res.data.get('latest_data'):
            return res.data['latest_data'].get('date')
    except Exception as e:
        print(f"âš ï¸ ë¶„ì„ ë‚ ì§œ í™•ì¸ ì¤‘ ì—ëŸ¬ (ë¬´ì‹œ ê°€ëŠ¥): {e}")
    return None

def main():
    # 1. ê° í…Œì´ë¸”ì˜ ìµœì‹  ë‚ ì§œ í™•ì¸
    latest_history_date = get_latest_date_from_db()
    latest_analysis_date = get_latest_analysis_date_from_db()
    
    print(f"ğŸ“… íˆìŠ¤í† ë¦¬ ìµœì‹  ë‚ ì§œ: {latest_history_date}")
    print(f"ğŸ¤– ë§ˆì§€ë§‰ ë¶„ì„ ë‚ ì§œ: {latest_analysis_date}")

    # 2. ë°ì´í„° ìˆ˜ì§‘ (ìµœì‹  ë‚ ì§œê°€ ì—†ìœ¼ë©´ ì²˜ìŒë¶€í„°, ìˆìœ¼ë©´ 1í˜ì´ì§€ë§Œ)
    fetch_pages = 1 if latest_history_date else 15
    scraped_data = fetch_credit_balance_history(pages=fetch_pages)
    
    # 3. ìƒˆë¡œìš´ ë°ì´í„° í•„í„°ë§ ë° ë™ê¸°í™”
    new_data = []
    if scraped_data:
        if latest_history_date:
            new_data = [item for item in scraped_data if item['date'] > latest_history_date]
        else:
            new_data = scraped_data

    if new_data:
        print(f"âœ¨ {len(new_data)}ê°œì˜ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sync_to_supabase(new_data)
        # ë°ì´í„°ê°€ ì¶”ê°€ë˜ì—ˆìœ¼ë¯€ë¡œ ìµœì‹  ë‚ ì§œ ë‹¤ì‹œ ê°±ì‹ 
        latest_history_date = get_latest_date_from_db()
    else:
        print("âœ… íˆìŠ¤í† ë¦¬ëŠ” ì´ë¯¸ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.")

    # 4. ë¶„ì„ ì‹¤í–‰ ì—¬ë¶€ íŒë‹¨ (ë°ì´í„° ìˆ˜ì§‘ê³¼ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰)
    if latest_history_date and (latest_history_date != latest_analysis_date):
        print(f"ğŸš€ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤. ({latest_analysis_date} -> {latest_history_date})")
        try:
            res = supabase.table("credit_balance_history").select("*").order("date", desc=False).execute()
            history_df = pd.DataFrame(res.data)
            
            if not history_df.empty:
                latest_record = history_df.iloc[-1].to_dict()
                analysis_res = analyze_credit_sentiment(history_df)
                
                if analysis_res:
                    update_analysis(analysis_res, latest_record)
                    print(f"âœ… {latest_record['date']} ê¸°ì¤€ ë¶„ì„ ì™„ë£Œ")
                    
                    # í‘¸ì‹œ ì•Œë¦¼ ì „ì†¡
                    try:
                        send_push_to_all(
                            title="ğŸ¦ ì‹ ìš©ìœµì ì”ê³  ì—…ë°ì´íŠ¸",
                            body=f"ì‹ ê·œ ë°ì´í„°({latest_record['date']})ê°€ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹œì¥ì˜ 'ë¹šíˆ¬' ì‹¬ë¦¬ ë¶„ì„ì„ í™•ì¸í•˜ì„¸ìš”.",
                            url="/credit-balance"
                        )
                    except Exception as e:
                        print(f"Failed to send push: {e}")
        except Exception as e:
            print(f"âŒ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì¤‘ ì—ëŸ¬: {e}")
    else:
        print("âœ… ë¶„ì„ ê²°ê³¼ê°€ ì´ë¯¸ ìµœì‹  ë°ì´í„°ì™€ ì¼ì¹˜í•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
